{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aafc3286-9cb5-46f8-931f-6113304b8e9b",
   "metadata": {},
   "source": [
    "# Mineral segmentation\n",
    "*Jordan Lubbers*\n",
    "\n",
    "## Motivation\n",
    "This notebook outlines how to take a series of CT images that represent a 3D volume and segment them using the watershed algorithm. In brief the pipeline is as follows:\n",
    "1. Import data. \n",
    "   - .tif, .png, or .jpg images\n",
    "   - downsample the data if required\n",
    "2. Rescale and normalize data so that pixel values are between 0 and 1\n",
    "3. Denoise the data\n",
    "   - allows for easier phase identification in histograms\n",
    "4. Create an elevation map of the image using image gradient algorithms\n",
    "   - accepts all methods found in scikit-image: 'sobel', 'roberts', 'scharr', 'prewitt'\n",
    "5. Choose marker values as starting points for the watershed segmentation algorithm\n",
    "6. Run the watershed segmentation algorithm\n",
    "7. Export data\n",
    "   - image stack (e.g., .png, .tif, .npy)\n",
    "   - segmentation metadata (i.e., all user decisions) for reproducibility\n",
    "   \n",
    "This notebook utilizes the module ```ctpy``` to accomplish the above tasks. For a \"from scratch\" version please see the ```mineral_segmentation_fromscratch.ipynb``` notebook\n",
    "   \n",
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b47952-3c36-4f68-bc75-900502476b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctpy as ct\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28e643-22f7-41ad-811d-1b3997f15dd1",
   "metadata": {},
   "source": [
    "## Import data\n",
    "Here we will import and also downsample our data so that it is more manageable on a standard personal computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28245b1b-8eea-41e6-bb15-f6d53761c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder where your 2D images reside\n",
    "filepath = \"/Volumes/JEL/Jorgenson_CT_work/0009_20CJ04_x7_A/stacks\"\n",
    "\n",
    "# For figure labeling and saving purposes\n",
    "name = \"0009_20CJ04_x7_A\"\n",
    "\n",
    "stack, original_stack_shape = import_stack(filepath, \"tif\", name, downsample=2)\n",
    "stack_1D = stack.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fed8c7-f02f-48c9-8a9f-46ac2bd8fa22",
   "metadata": {},
   "source": [
    "## Rescale the stack\n",
    "Looking at our histogram we can see that there are a very small amount of pixels with values at the far high end of the attenuation range. Because these pixels encompass negligible proportions of our data we are going to remove them to better fill the normalized range. This is known as contrast stretching and should allow us to see subtleties in our data better. We normalize the data because Python's ```sckit-image``` processing functions tend to work better with values between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb635b-8faf-482b-90fe-f3e8b7e3301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_lim, upper_lim = 0.05, 99.97\n",
    "plow, phigh, stack_normal, stack_normal_1D = rescale_stack(lower_lim, upper_lim, stack)\n",
    "\n",
    "\n",
    "# plot up the comparison between original stack and rescaled stack\n",
    "cmap = \"viridis\"\n",
    "scale = \"linear\"\n",
    "\n",
    "#halfway through the stack\n",
    "slice_number = stack.shape[0] // 2\n",
    "\n",
    "fig, ax, = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "ax[0, 0].hist(stack_1D, bins=100, color=\"gray\")\n",
    "ax[0, 0].set_title(\"Stack Histogram\", fontsize=20)\n",
    "ax[0, 0].set_yscale(scale)\n",
    "ax[0, 0].axvline(phigh, c=\"r\", label=\"{}% of data\".format(upper_lim))\n",
    "ax[0, 0].axvline(plow, c=\"g\", label=\"{}% of data\".format(lower_lim))\n",
    "ax[0, 0].legend(loc=\"best\", title=\"percentile\")\n",
    "ax[0, 0].set_ylabel(\"counts\", fontsize=14)\n",
    "ax[0, 0].set_xlabel(\"pixel value\", fontsize=14)\n",
    "\n",
    "# show the first image of the stack\n",
    "ax[0, 1].imshow(stack[slice_number], cmap=cmap)\n",
    "ax[0, 1].set_title(\"Slice {} of stack\".format(slice_number))\n",
    "\n",
    "# rescaled data\n",
    "\n",
    "ax[1, 0].hist(stack_normal_1D, bins=100, color=\"gray\")\n",
    "ax[1, 0].set_yscale(scale)\n",
    "ax[1, 0].set_ylabel(\"counts\", fontsize=14)\n",
    "ax[1, 0].set_xlabel(\"rescaled pixel value\", fontsize=14)\n",
    "ax[1, 0].set_title(\"Normalized and rescaled stack\", fontsize=20)\n",
    "ax[1, 0].set_xlim(0, 1)\n",
    "# show the first image of the stack\n",
    "ax[1, 1].imshow(stack_normal[slice_number], cmap=cmap)\n",
    "ax[1, 1].set_title(\"Slice {} of rescaled stack\".format(slice_number))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21959a9-20d7-458e-be7e-c58206c7d567",
   "metadata": {},
   "source": [
    "## Inspect stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7dc51-78fc-402e-ace4-ad2d6e5a4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 4, figsize=(20, 20))\n",
    "axes = ax.ravel()\n",
    "\n",
    "for i, a in zip(np.linspace(1, stack.shape[0], 20), axes):\n",
    "    a.imshow(stack_normal[int(i - 1), :, :], vmin=0, vmax=1)\n",
    "    a.set_title(\"Slice: {}\".format(int(i - 1)), fontsize=16)\n",
    "fig.suptitle(\n",
    "    \"Rescaled stack at {} slice increments\".format(\n",
    "        int(\n",
    "            np.linspace(1, stack.shape[0], 20)[1]\n",
    "            - np.linspace(1, stack.shape[0], 20)[0]\n",
    "        )\n",
    "    ),\n",
    "    fontsize=24,\n",
    "    y=0.92,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1dcad-a4b8-4266-8478-da98a4c0c587",
   "metadata": {},
   "source": [
    "## Refine histogram peaks with non-local means denoising\n",
    "Denoising the stack with the non-local means algorithm allows for image noise to be removed while still preserving crucial textural information. This noise removal also allows for unique phases (i.e., histogram peaks) to be identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d5a60-89dd-4ed5-b6ae-834083a55a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the non local means denoising helper function\n",
    "# and specify the patch size and distance\n",
    "patch_size = 10\n",
    "patch_distance = 10\n",
    "stack_nlm, stack_nlm_1D = denoise_stack(stack_normal, patch_size, patch_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01805659-21c8-4055-b7b4-e047fe71bc8a",
   "metadata": {},
   "source": [
    "### Compare pre and post denoised slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca1ae5-cec9-44c3-9d3c-c1dacc232f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.get_cmap(cmap)\n",
    "slice_nlm_1D = stack_nlm[slice_number].flatten()\n",
    "slice_1D = stack_normal[slice_number].flatten()\n",
    "\n",
    "bins = 200\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10), gridspec_kw={\"width_ratios\": [2, 1],})\n",
    "fig.suptitle(\n",
    "    \"Comparing slice {} before and after denoising \\n {}\".format(slice_number, name),\n",
    "    fontsize=18,\n",
    ")\n",
    "\n",
    "# Histogram for rescaled image\n",
    "counts, bins, patches = ax[0, 0].hist(slice_1D, bins=bins,)\n",
    "ax[0, 0].minorticks_on()\n",
    "ax[0, 0].set_xlim(0, 1)\n",
    "ax[0, 0].set_ylabel(\"counts\", fontsize=20)\n",
    "ax[0, 0].set_title(\"Rescaled Image\", fontsize=20, y=0.85)\n",
    "\n",
    "# get the value for center of bins\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "# color the histogram by value\n",
    "for c, p in zip(bin_centers, patches):\n",
    "    plt.setp(p, \"facecolor\", colormap(c))\n",
    "\n",
    "# rescaled image\n",
    "ax[0, 1].imshow(stack_normal[slice_number], cmap=cmap)\n",
    "ax[0, 1].axes.yaxis.set_ticklabels([])\n",
    "ax[0, 1].axes.yaxis.set_ticks([])\n",
    "ax[0, 1].axes.xaxis.set_ticklabels([])\n",
    "ax[0, 1].axes.xaxis.set_ticks([])\n",
    "\n",
    "# Histogram for non local means image\n",
    "counts2, bins2, patches2, = ax[1, 0].hist(slice_nlm_1D, bins=bins,)\n",
    "\n",
    "# get value for center of bins\n",
    "bin_centers2 = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "# color the histogram by value\n",
    "for c, p in zip(bin_centers2, patches2):\n",
    "    plt.setp(p, \"facecolor\", colormap(c))\n",
    "ax[1, 0].minorticks_on()\n",
    "ax[1, 0].set_ylim(0, 1.05 * np.max(counts2))\n",
    "\n",
    "ax[1, 0].set_xlim(0, 1)\n",
    "ax[1, 0].set_xlabel(\"normalized pixel value\", fontsize=14)\n",
    "ax[1, 0].set_title(\"Non-local Means image\", fontsize=20, y=0.85)\n",
    "ax[1, 0].set_ylabel(\"counts\", fontsize=20)\n",
    "\n",
    "\n",
    "# non local means image\n",
    "ax[1, 1].imshow(stack_nlm[slice_number], cmap=cmap)\n",
    "ax[1, 1].axes.yaxis.set_ticklabels([])\n",
    "ax[1, 1].axes.yaxis.set_ticks([])\n",
    "ax[1, 1].axes.xaxis.set_ticklabels([])\n",
    "ax[1, 1].axes.xaxis.set_ticks([])\n",
    "ax[1, 0].set_ylim(0, 1.05 * np.max(counts2))\n",
    "ax[0, 0].set_ylim(0, 1.05 * np.max(counts2))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a36d8e-5cd9-4e37-9e80-27507d03d98e",
   "metadata": {},
   "source": [
    "### Compare pre and post denoised stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd18c88-0032-42e2-96e5-50bb4b144da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "counts, bins, patches = ax[0].hist(stack_normal_1D, bins=bins,)\n",
    "ax[0].set_title(\"Noisy Stack Histogram\", fontsize=20)\n",
    "ax[0].set_xlabel(\"normalized pixel value\", fontsize=20)\n",
    "ax[0].set_ylabel(\"counts\", fontsize=20)\n",
    "ax[0].minorticks_on()\n",
    "\n",
    "\n",
    "counts2, bins2, patches2 = ax[1].hist(stack_nlm_1D, bins=bins,)\n",
    "\n",
    "# make histograms colored by normalized pixel value\n",
    "# first histogram\n",
    "# get the value for the center of the bins\n",
    "bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "# color the histogram by value\n",
    "for c, p in zip(bin_centers, patches):\n",
    "    plt.setp(p, \"facecolor\", colormap(c))\n",
    "\n",
    "# second histogram\n",
    "bin_centers2 = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "# color the histogram by value\n",
    "for c, p in zip(bin_centers2, patches2):\n",
    "    plt.setp(p, \"facecolor\", colormap(c))\n",
    "\n",
    "ax[1].set_title(\"Denoised Stack Histogram\", fontsize=20)\n",
    "ax[1].set_xlabel(\"normalized pixel value\")\n",
    "ax[1].minorticks_on()\n",
    "# ax[0].set_yscale('log')\n",
    "# ax[1].set_yscale('log')\n",
    "ax[0].set_ylim(0, np.max(1.05 * counts2))\n",
    "ax[1].set_ylim(0, np.max(1.05 * counts2))\n",
    "ax[0].set_xlim(0, 1)\n",
    "ax[1].set_xlim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f8872-ba5c-42ff-bdfc-89b19a956913",
   "metadata": {},
   "source": [
    "## Create elevation map for watershed markers\n",
    "\n",
    "A brief blurb on the watershed algorithem from [Roerdink and Meijster, 2000](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.10.3852&rep=rep1&type=pdf):\n",
    "\n",
    "\"The watershed transform can be classified as a region-based segmentation approach. The intuitive idea underlying this method comes from geography: it is that of a landscape or topographic relief which is flooded by water, watersheds being the divide lines of the domains of attraction of rain falling over the region [46]. An alternative approach is to imagine the landscape being immersed in a lake, with holes pierced in local minima. Basins (also called ‘catchment basins’) will fill up with water starting at these local minima, and, at points where water coming from different basins would meet, dams are built. When the water level has reached the highest peak in the landscape, the process is stopped. As a result, the landscape is partitioned into regions or basins separated by dams, called watershed lines or simply watersheds.\"\n",
    "\n",
    "\n",
    "Here we use the [sobel](https://scikit-image.org/docs/dev/auto_examples/edges/plot_edge_filter.html#sphx-glr-auto-examples-edges-plot-edge-filter-py) edge filter to make an \"elevation map\" as in this [example](https://scikit-image.org/docs/0.12.x/auto_examples/xx_applications/plot_coins_segmentation.html#region-based-segmentation) which represents the image gradient at each pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490183d4-a8ce-468e-a08f-95c1da573bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_algorithm = \"sobel\"\n",
    "elevation_map = create_elevation_map(stack_nlm, method=elevation_algorithm)\n",
    "\n",
    "slice_number = 99\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "m = ax.imshow(elevation_map[slice_number], cmap=cmap)\n",
    "ax.set_title(\"Elevation Map \\n slice number: {}\".format(slice_number), fontsize=20)\n",
    "\n",
    "cbar = fig.colorbar(m, ax=ax, shrink=0.75,)\n",
    "cbar.set_label(label=\"normalized gradient\", fontsize=16)\n",
    "\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c5e172-6cb8-4405-8b0a-9c25029ac6cd",
   "metadata": {},
   "source": [
    "## Pick your markers for the segmentation\n",
    "\n",
    "Although we apply the watershed algorithm to the elevation map created above, we first need to define our markers! Think of the algorithm starting at these markers and moving out (up) from there, classifying the image not just by pixel value, but it's topographical location relative to the pixels around it. Because this adds in a spatial component to the image segmentation, it often times produces more accurate results than simple thresholding. Based on the histogram above you will determine the number of segments for your image (i.e. background, sample holder, phase 1, phase 2, etc.). To set watershed markers, in brief, we create a new array that is the same shape as our stack, but fill it with 0s. We are then going to replace those 0s with 'marker' values for a certain pixel range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e7164-c169-455f-b4c2-b6a6d6daa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clasify the number of phases here and their normalized\n",
    "#pixel limits. Note that for intermediate value phases\n",
    "#you must specify a lower and upper limit\n",
    "phase1_limit = [0.5]\n",
    "phase2_limit = [0.6, 0.67]\n",
    "phase3_limit = [0.7, 0.83]\n",
    "phase4_limit = [0.84]\n",
    "\n",
    "phase_limits = [phase1_limit, phase2_limit, phase3_limit, phase4_limit]\n",
    "\n",
    "markers = add_markers(stack_nlm, phase_limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0d644-ff4d-41e6-92f3-84d875c88d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "m = ax[0].imshow(markers[slice_number], cmap=cmap)\n",
    "ax[0].set_title(\"Markers\", fontsize=20)\n",
    "bounds = np.linspace(0, 5, 6)\n",
    "\n",
    "cbar = fig.colorbar(m, ax=ax[0], ticks=bounds, shrink=0.6,)\n",
    "cbar.set_label(label=\"marker value\", fontsize=16)\n",
    "ax[1].imshow(stack_nlm[slice_number], cmap=cmap)\n",
    "ax[1].set_title(\"Denoised Data\", fontsize=20)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278adcf7-df2c-4f07-b91f-eaeecc27cd9c",
   "metadata": {},
   "source": [
    "## Run the watershed segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc4042-0952-4855-86f7-9e9bcbcb83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_results = run_watershed_segmentation(elevation_map, markers)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(stack_nlm[slice_number], cmap=cmap, interpolation=\"nearest\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[0].set_title(\"Smoothed data\", fontsize=20)\n",
    "ax[1].imshow(markers[slice_number], cmap=cmap, interpolation=\"nearest\")\n",
    "ax[1].axis(\"off\")\n",
    "ax[1].set_title(\"Markers\", fontsize=20)\n",
    "ax[2].imshow(ws_results[slice_number], cmap=cmap, interpolation=\"nearest\")\n",
    "ax[2].axis(\"off\")\n",
    "ax[2].set_title(\"Segmentation\", fontsize=20)\n",
    "\n",
    "fig.subplots_adjust(hspace=0.01, wspace=0.01, top=1, bottom=0, left=0, right=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a8fd2-4f81-474e-a918-a7100994feed",
   "metadata": {},
   "source": [
    "## Save results and make a report of all requisite metadata\n",
    "Here we'll save the data as a stack of .tif files that represent the segmented images. We also save the metadata (e.g., all the input decisions made in the pipeline) to be reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceec400-58ea-4eab-a8f5-401428a72ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = \"/Volumes/JEL/Jorgenson_CT_work/0009_20CJ04_x7_A/\"\n",
    "\n",
    "save_seg_results(outpath, name, ws_results, cmap)\n",
    "save_metadata(outpath, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5352af6f-042e-4803-9198-b179e042b4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47200a3-a362-48de-84a0-2ef8fc36db97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
